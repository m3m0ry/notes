{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Discrete Probability Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports, variables, functions, distributions and approximations used in code for this chapter\n",
    "import sympy as sp\n",
    "import sympy.plotting as plot\n",
    "import mpmath as mp\n",
    "sp.init_printing()\n",
    "x, N = sp.symbols('x, N')\n",
    "a, b, c = sp.symbols('a, b, c')\n",
    "sigma, mu = sp.symbols('sigma, mu') \n",
    "stirling_approx = sp.sqrt(2*mp.pi*N)* (N/mp.e)**N\n",
    "gosper_approx = mp.e**(-N) * N**N * sp.sqrt((2*N + 1/3)*mp.pi)\n",
    "gaussian = a * mp.e**-((x-b)**2/(2*c**2))\n",
    "gaussian_distribution = gaussian.subs([(a, 1/sp.sqrt(2*mp.pi*sigma**2)), (b, mu), (c, sigma)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 What is Probability?\n",
    "- Frequentists: $ N_s:$ Number of successes; $ N:$ Number of tries\n",
    "$$ p = \\lim_{N \\to \\infty}\\frac{N_s}{N} $$\n",
    "\n",
    "- Bayesians: description of a person's knowledge of the outcome of a trial\n",
    "\n",
    "- \"Model Probability\": what the frequency of success would be for an infinite number of trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Discrete Random Variables and Probabilities\n",
    "- Set of events: $A = \\{a_j| j = 1, N_A\\}$\n",
    "- each event has probability $ 0 \\leq P(a_j) \\leq 1 $\n",
    "- normalization condition: $ \\sum_a P(a) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Probability Theory for Multiple Random Variables\n",
    "- $A = \\{a_j| j = 1, N_A\\}; B = \\{b_k| k = 1, N_B\\}$\n",
    "- joint probability: $0 \\leq P(a_j, b_k) \\leq 1; \\sum_a \\sum_b P(a,b) = 1$\n",
    "### 3.3.1 Marginal and Conditional Probability\n",
    "- Marginal Probability: $P_A(a) = \\sum_b P(a,b)$ (satisfies positivity and normalization criteria)\n",
    "- Conditional probability: probability of $a$, given that $b$ has occured $P(a|b) = \\frac{P(a,b)}{P_B(b)}$\n",
    "\n",
    "   $P(a,b) = P(a|b)P_B(b) = P(b|a)P_A(a)$\n",
    "- Bayes' theorem: $P(a|b) = \\frac{P(b|a)P_A(a)}{P_B(b)}$\n",
    "### 3.3.2 Independent Variables\n",
    "- If $P(a,b) = P_A(a)P_B(b)$ is true then $a$ and $b$ are indipendent, furthermore: $P(a|b) = P_A(a)$\n",
    "### 3.3.3 Pairwise Independence and Mutual Independence\n",
    "- Pairwise independence: marginal distribution of any pair of random variables can be written as the product of the marginal distribution of the individual random varibales\n",
    "- Mutual independence: same like Pairwise, but for any subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Random numbers and Functions of Random Variables\n",
    "- Random variable: $A = \\{a_j|j = 1, \\dots, N_A\\}$\n",
    "- Numerical function: $F = \\{F(a_j)|1,\\dots, N_A\\}$\n",
    "- Set of random numbers $F$ together with their properties, is then also a random number\n",
    "- Probability distribution of $F$: $P_F(f) = \\sum_a \\delta_{f, F(A)} P_A(a)$\n",
    "- Combination of random numbers: $P_G(g) = \\sum_x \\sum_y \\delta_{g,G(x,y)} P(x,y)$\n",
    "\n",
    "*TODO example 21-22*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Mean, Variance, and Standard Deviation\n",
    "- Mean or Average: $ \\mu = \\langle F \\rangle \\equiv  \\sum_a F(a) P_A(a)$ \n",
    "- n-th moment: $\\langle F^n \\rangle \\equiv \\sum_a F(a)^n P_A(a)$\n",
    "- n-th central moment: $\\langle (F - \\langle F \\rangle)^n \\rangle \\equiv \\sum_a (F(a) - \\langle F \\rangle )^n P_A(a)$\n",
    "- Variance, second central moment: $\\sigma^2 = \\langle (F - \\langle F \\rangle)^2 \\rangle \\equiv \\sum_a (F(a) - \\langle F \\rangle )^2 P_A(a) \\Rightarrow \\langle F^2 \\rangle - \\langle F \\rangle ^2$\n",
    "- Standard deviation, often as a measure of the width of a probability distribution: $\\sigma \\equiv \\sqrt{\\langle F^2 \\rangle - \\langle F \\rangle ^2}$\n",
    "\n",
    "*TODO own examples*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Correlation Functions\n",
    "- Correlation Function: $f_{FG} = \\langle FG \\rangle - \\langle F \\rangle \\langle G \\rangle$\n",
    "- If $F$ and $G$ independent -> $f_{FG}$ vanishes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Sets of Independent Random Numbers\n",
    "- New random number as sum of random number: $S = \\sum_j F_j$\n",
    "- Mean of S: $\\langle S \\rangle = \\langle \\sum_j F_j \\rangle = \\sum_j \\langle F \\rangle$\n",
    "- If pairwise independent: $\\sigma^2 = \\langle S^2 \\rangle - \\langle S \\rangle ^2 = \\dots = \\sum_j \\sigma^2_j$\n",
    "- If $F_j$ have same mean and variance: $\\langle S \\rangle = \\sum_j \\langle F_j \\rangle = N \\langle F \\rangle; \\sigma^2_S = \\sum_j \\sigma^2_j = N \\sigma^2$\n",
    "- $\\Rightarrow \\sigma_s = \\sigma N$\n",
    "- Relative standard deviation: $\\frac{\\sigma_s}{\\langle S \\rangle} = \\frac{\\sigma}{\\langle F \\rangle \\sqrt{N}}$\n",
    "- This is very important for statistical mechanics, since with $N \\geq 10^{20}$ uncertainties for macroscipic quantities are $\\leq 10^{-10}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Binomial Distribution\n",
    "- N independent, identically distributed random numbers, either $0$ or $1$, where $P(1) = p; P(0) = 1-p$\n",
    "- Mean: $\\langle F \\rangle = p$\n",
    "- Variance: $\\sigma^2 = p(1-p)$\n",
    "- Mean of the sum: $S = \\sum_j F_j = pN$\n",
    "- Variance of the sum: $\\sigma^2_S = p(1-p)N$\n",
    "- Standard deviation of the sum: $\\sigma_S = \\sqrt{p(1-p)n}$\n",
    "- Relative standard deviation of the sum: $\\frac{\\sigma_S}{\\langle S \\rangle} = \\sqrt{\\frac{1-p}{N}}$\n",
    "\n",
    "### 3.8.1 Derivation of the Binomial Distribution\n",
    "- Calculate explicit probability distribution $P(S)$\n",
    "- Specific subset: $p^n (1-p)^{N-n}$\n",
    "- Number of permutations: $\\binom{N}{n} = \\frac{N!}{n!(N-n)!}$\n",
    "- Binomail Distribution: $P(n|N) = \\binom{N}{n} p^n(1-p)^{N-n}$\n",
    "- (Name from binomial theorem)\n",
    "\n",
    "### 3.8.1 Useful Identities for the Binomial Coefficients\n",
    "- $\\binom{N}{0} = \\binom{N}{N} = 1$\n",
    "- $\\binom{N-1}{n} + \\binom{N-1}{n-1} = \\binom{N}{n}$\n",
    "- $\\binom{N}{n+1} = \\frac{N-n}{n+1} \\binom{N}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Gaussian Approximation to the Binomial Distribution\n",
    "- Gaussian function: $\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp{\\left[-\\frac{(x-x_o)^2}{2\\sigma^2}\\right]}  \\left(= a e^{-\\frac{(x-b)^2}{2c^2}}\\right)$\n",
    "- Mean and maximum: $\\langle x \\rangle = x_o = x_{max}$\n",
    "- Variance: $\\langle (x-x_o)^2 \\rangle = \\dots = \\sigma^2$\n",
    "- Gaussian approximation to the binomial distribution: $\\langle n \\rangle = pN; \\sigma^2 = p(1-p)N$\n",
    "$$\\Rightarrow P(n|N) \\approx \\frac{1}{\\sqrt{2\\pi p(1-p)N}}\\exp\\left[-\\frac{(n-pN)^2}{2p(1-p)N}\\right] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p0 = plot.plot(gaussian_distribution.subs([(mu, 5), (sigma**2, 5)]), (x, -5, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.10 A Digression on Gaussian Integrals\n",
    "- Needed good approximation for $N!$\n",
    "- Gaussian Integral: $G = \\int_{-\\infty}^{\\infty} e^{-ax^2}dx = \\dots = \\sqrt{\\frac{\\pi}{a}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 Stirling's Approximation for $N!$\n",
    "- Approximation for large $N$\n",
    "### 3.11.1 The Simplest Version of Stirling's Approximation\n",
    "$$\\ln N! = \\ln \\left( \\prod_{n=1}^N \\right) = \\sum_{n=1}^N \\ln(n) \\approx \\int_1^N \\ln(x)dx = N \\ln N - N + 1$$\n",
    "$$ \\Rightarrow N! \\approx N^N \\exp^{(1-n)}$$\n",
    "### 3.11.2 A Better Version of Stirling's Approximation\n",
    "- Exact integral representation: $N! = \\int_0^{\\infty} e^{-x} x^N dx$ (correctness shown with induction, i.e. show for $N=0$ and $N+1$)\n",
    "- Integral approximation for large $N \\Rightarrow$ Integrand is sharply peaked: Gaussian function\n",
    "- $a; b = x_0; c = \\sigma$ as constants, which must be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "integral = mp.e**-x * x**N\n",
    "p1 = plot.plot(integral.subs(N,10), integral.subs(N,9), integral.subs(N,8), (x, 0, 25), show=False)\n",
    "p1[0].line_color = 'blue'\n",
    "p1[1].line_color = 'green'\n",
    "p1[2].line_color = 'grey'\n",
    "p2 = plot.plot(gaussian.subs([(a,455000), (b,10), (c,2.8)]), (x, 0, 25), show = False)\n",
    "p2[0].line_color = 'red'\n",
    "p1.extend(p2)\n",
    "p1.title = 'Example: Gaussian (red) and Integrands'\n",
    "p1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First derivative of the integrand and Gaussian function: $\\Rightarrow x = x_o = N$\n",
    "- Evaluated: $\\Rightarrow a = e^{-N}N^N$\n",
    "- Second derivative of Gaussian function and integrand: $\\Rightarrow \\sigma^2 = \\frac{x_o^2}{N} = N$\n",
    "- Use this approximation in original formula for integral\n",
    "$$N! = \\int_0^{\\infty} e^{-x} x^N dx \\approx \\int_0^{\\infty} e^{-N}N^N \\exp \\left[ -\\frac{(x-N)^2}{2N}\\right] dx \\approx e^{-N}N^N \\sqrt{2\\pi N}$$\n",
    "## 3.11.3 Gosper's Approximation\n",
    "- Even better approximation for small $N$: $N! \\approx e^{-N}N^N\\sqrt{(2N+\\frac{1}{3})\\pi}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p3 = plot.plot(stirling_approx, gosper_approx, (N, 0, 3), show = False)\n",
    "p4 = plot.plot(sp.factorial(N), (N, 0, 3), show = False)\n",
    "p3.extend(p4)\n",
    "p3[0].line_color = 'red'\n",
    "p3[1].line_color = 'black'\n",
    "p3[2].line_color = 'yellow'\n",
    "p3.title = 'Stirling approximation red, Gosper black, Factorial blue'\n",
    "p3.show()\n",
    "p5 = plot.plot(sp.Abs(stirling_approx - sp.factorial(N))/sp.Abs(sp.factorial(N)), (N, 0, 10), title = 'Relative error, blue: stirling, red: gosper', show = False)\n",
    "p6 = plot.plot(sp.Abs(gosper_approx - sp.factorial(N))/sp.Abs(sp.factorial(N)), (N, 0, 10), show = False)\n",
    "p5.extend(p6)\n",
    "p5[1].line_color = 'red'\n",
    "p5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11.4 Using Stirling's Approximation\n",
    "- In statistical mechanics $10^{12} \\leq N \\leq 10^{20}$ and often $\\ln N$\n",
    "- $\\Rightarrow$ for such large values, even the error of the simple Stirling's approximation is negligible\n",
    "- $\\ln N! \\approx N \\ln N - N \\Rightarrow$ accurate enough\n",
    "- (notice that Gosper has $\\ln N\\approx N \\ln N - N + \\frac{1}{2}\\left[(2N+\\frac{1}{3})\\pi\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 Binomial Distribution with Stirling's Approximation\n",
    "- Reminder Binomial Distribution: $P(n|N) = \\frac{N!}{n!(N-n)!}p^n(1-p)^{N-n}$\n",
    "- $\\ln P(n|N) \\approx N\\ln N - n\\ln n - (N-n)\\ln(N-n) + n\\ln p + (N-n)\\ln(1-p)$\n",
    "- Task: Find peak of Binomial Distribution\n",
    "- Solution: $\\frac{\\partial}{\\partial n}\\ln P(n|N) = 0$\n",
    "- $\\Rightarrow -\\ln n + \\ln(N-n) + \\ln p - \\ln(1-p)$\n",
    "- $\\Rightarrow n_o = pN$\n",
    "- $\\Rightarrow \\langle n \\rangle = pN$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
