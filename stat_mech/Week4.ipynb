{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling and Integration - From Gaussians to the Maxwell and Boltzmann distributions\n",
    "## Integration and Sampling\n",
    "- Connect Sampling to Integration\n",
    "- From Week1 $\\frac{\\pi}{4} \\approx \\frac{\\text{#hits}}{\\text{#trials}} = \\frac{1}{\\text{#trials}} \\sum_i O_i$\n",
    "- $\\rightarrow \\frac{\\pi}{4} = \\frac{\\int_{-1}^1 \\int_{-1}^1 dx dy O(x,y) \\pi(x,y)}{\\int_{-1}^1 \\int_{-1}^1 dx dy \\pi(x,y)}$\n",
    "- $O(x,y) = \\begin{cases}1 & x^2 + y^2 \\leq 1\\\\ 0 & \\text{otherwise}\\end{cases}$\n",
    "- $\\pi(x,y) = 1$ (uniform probability distribution on the square)\n",
    "- With Monte-Carlo we compute $\\int_{-1}^1 \\int_{-1}^1 dx dy \\pi(x,y)$\n",
    "- However at: $\\frac{1}{\\text{#trials}} \\sum_i O_i$ the distribution $\\pi(x,y)$ is absent\n",
    "- $\\rightarrow$ samples i, which are drawn from this distribution\n",
    "- $\\Rightarrow$ the integral of two dimensions dissapears\n",
    "- $\\rightarrow$ no multiple sums along all dimensions\n",
    "- $\\rightarrow$ Monte-Carlo excells at high dimension\n",
    "\n",
    "## Gaussian integral\n",
    "- $I = \\int_{-\\infty}^{+\\infty} \\frac{dx}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}x^2} = 1$\n",
    "- $I^2 = \\left(\\int_{-\\infty}^{+\\infty} \\frac{dx}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}x^2}\\right)^2$\n",
    "- $ = \\int_{-\\infty}^{+\\infty} \\frac{dx}{\\sqrt{2\\pi}} \\int_{-\\infty}^{+\\infty} \\frac{dy}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} x^2} e^{-\\frac{1}{2}y^2}$\n",
    "- Substitution:\n",
    "    - $x = r \\cos(\\phi)$\n",
    "    - $y = r \\sin(\\phi)$\n",
    "    - $dx dy = r dr d\\phi$\n",
    "- $I^2 = \\int_{-\\infty}^{+\\infty} \\frac{dx}{\\sqrt{2\\pi}} \\int_{-\\infty}^{+\\infty} \\frac{dy}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} [x^2+y^2]} = \\int_0^{2\\pi} \\frac{d\\phi}{2\\pi} \\int_0^{\\infty} dr r e^{-\\frac{1}{2} r^2}$\n",
    "- Substitution:\n",
    "    - $r = \\sqrt{2\\psi}$\n",
    "    - $dr = d\\psi$\n",
    "- $ = \\int_0^{2\\pi} \\frac{d\\phi}{2\\pi} \\int_0^{\\infty} d\\psi e^{-\\psi}$\n",
    "- Substitution:\n",
    "    - $e^{-\\psi} = \\Upsilon$\n",
    "    - $d \\psi = d \\Upsilon$\n",
    "- $= \\int_0^{2\\pi} \\frac{d\\phi}{2\\pi} \\int_0^1 d\\Upsilon$  (both integrals are 1)\n",
    "- $ = 1 \\Rightarrow I = 1$\n",
    "\n",
    "\n",
    "- Sampling instead\n",
    "    - $\\phi$ is a random number between $0$ and $2\\pi$\n",
    "    - $\\Upsilon$ is a random number between $0$ and $1$\n",
    "- Samples $\\phi$ and $\\Upsilon$ give samples $\\phi$ and $\\psi$ ....$x$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, math, pylab\n",
    "\n",
    "def gauss_test(sigma):\n",
    "    phi = random.uniform(0.0, 2.0 * math.pi)\n",
    "    Upsilon = random.uniform(0.0, 1.0)\n",
    "    Psi = - math.log(Upsilon)\n",
    "    r = sigma * math.sqrt(2.0 * Psi)\n",
    "    x = r * math.cos(phi)\n",
    "    y = r * math.sin(phi)\n",
    "    return [x, y]\n",
    "\n",
    "# exact distrubution:\n",
    "list_x = [i * 0.1 for i in range(-40, 40)]\n",
    "list_y = [math.exp(- x ** 2 / 2.0) / (math.sqrt(2.0 * math.pi)) for x in list_x]\n",
    "# sampled distribution:\n",
    "n_sampled_pairs = 500000\n",
    "data = []\n",
    "for sample in range(n_sampled_pairs):\n",
    "        data += gauss_test(1.0)\n",
    "# graphics output\n",
    "pylab.plot(list_x, list_y, color='b', label='exact')\n",
    "pylab.hist(data, bins=150, normed=True, color='r', histtype='step', label='sampled')\n",
    "pylab.legend()\n",
    "pylab.title('Sampling of the gaussian distribution\\n(gauss_test_movie.py)')\n",
    "pylab.xlabel('$x$', fontsize=14)\n",
    "pylab.ylabel('$\\pi(x)$', fontsize=14)\n",
    "pylab.show()\n",
    "pylab.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Points in and on a Sphere\n",
    "- Consider vectors of gaussians (2D, 3D, ..)\n",
    "- (We use random.gauss, which is basically the same as our gauss_test. It uses Box-Muller method)\n",
    "- This distribution is isotropic (you can rotate it without changes) (in any dimmension), because $\\phi$ is just rotated around\n",
    "### Sphere surface\n",
    "- With a normalization we can use gauss distribution to obtain random points on a sphere (or hyper sphere)\n",
    "- $\\hat{x_i} = \\frac{x_i}{\\sqrt{\\sum_0^{N-1} x_j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, math, pylab, mpl_toolkits.mplot3d\n",
    "\n",
    "x_list, y_list, z_list = [], [], []\n",
    "nsamples = 1000\n",
    "for sample in range(nsamples):\n",
    "    x_list.append(random.gauss(0.0, 1.0))\n",
    "    y_list.append(random.gauss(0.0, 1.0))\n",
    "    z_list.append(random.gauss(0.0, 1.0))\n",
    "# begin graphics output\n",
    "fig = pylab.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_aspect('equal') # set the aspect ratio of the plot\n",
    "pylab.plot(x_list, y_list, z_list, '.')\n",
    "pylab.title('Samples from the 3D gaussian distribution')\n",
    "ax.set_xlabel('$x$', fontsize=14)\n",
    "ax.set_ylabel('$y$', fontsize=14)\n",
    "ax.set_zlabel('$z$', fontsize=14)\n",
    "pylab.show()\n",
    "pylab.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, math, numpy\n",
    "\n",
    "def hyper_sphere_surface(dimensions):\n",
    "    R = [random.gauss(0.0, 1.0) for d in range(dimensions)]\n",
    "    radius = math.sqrt(sum(x ** 2 for x in R))\n",
    "    return [x / radius for x in R]\n",
    "        \n",
    "dimensions = 3\n",
    "nsamples = 1000\n",
    "distribution = numpy.empty((nsamples, dimensions))\n",
    "for sample in range(nsamples):\n",
    "    distribution[sample] = hyper_sphere_surface(dimensions)\n",
    "fig = pylab.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_aspect('equal')\n",
    "pylab.plot(distribution[:,0], distribution[:,1], distribution[:,2], '.')\n",
    "pylab.title('Uniform sampling of the sphere surface')\n",
    "ax.set_xlabel('$x$', fontsize=14)\n",
    "ax.set_ylabel('$y$', fontsize=14)\n",
    "ax.set_zlabel('$z$', fontsize=14)\n",
    "pylab.show()\n",
    "pylab.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mathemtic explenation:\n",
    "- $1 = \\left(\\frac{1}{\\sqrt{2\\pi}}\\right)^d \\int \\dots \\int dx_0 \\dots dx_{d-1} e^{-\\frac{1}{2}(x_0^2 + \\dots + x_{d-1}^2)}$\n",
    "- Substitution\n",
    "    - $(x_0, \\dots, d_{d-1}) \\rightarrow (r,\\Omega)$\n",
    "    - $x_0^2 + \\dots + x_{d-1}^2 = r^2$ ($\\Omega$ is an angular variable. Integrated $\\Omega$ in 2D is $2\\pi$, in 3D $4\\pi$\n",
    "    - $dx_0 + \\dots + dx_{d-1} = r^{d-1} dr d\\Omega$\n",
    "- $= \\left( \\frac{1}{\\sqrt{2\\pi}} \\right)^d  \\int_0^{\\infty} dr r^{d-1} e^{-\\frac{1}{2} r^2} \\int d\\Omega$\n",
    "- Two independent integrals, no functions depepndeing on $\\Omega$\n",
    "\n",
    "### Sphere volume\n",
    "- After the normalization to sphere surface, we redistribute the coordinates again between 0 and 1\n",
    "- $\\pi(r) = r^{d-1} dr  \\quad(0<r<1) \\rightarrow$ `random.uniform(0.0, 1.0)**(1/d)`\n",
    "- ($\\hat{x_i} = \\frac{x_i}{\\sqrt{\\sum_0^{N-1} x_j}}$: surface)\n",
    "- $\\tilde{x_i} = \\hat{x_i} \\cdot \\pi(r)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, math, pylab, mpl_toolkits.mplot3d, numpy\n",
    "\n",
    "\n",
    "def hyper_sphere(dimmensions):\n",
    "    R = [random.gauss(0.0, 1.0) for d in range(dimensions)]\n",
    "    length = random.uniform(0.0, 1.0) ** (1.0 / dimensions) / math.sqrt(sum(x ** 2 for x in R))\n",
    "    return [x * length for x in R]\n",
    "\n",
    "dimensions = 3\n",
    "nsamples = 20000\n",
    "distribution = numpy.empty((nsamples, dimensions))\n",
    "i = 0\n",
    "for sample in range(nsamples):\n",
    "    out = hyper_sphere(dimensions)\n",
    "    z = out[2]\n",
    "# Limiting the output for graphical purposes\n",
    "    if z < 0.075 and z > -0.075 or z > 0.85 or z < -0.85:\n",
    "        distribution[i] = out\n",
    "        i += 1\n",
    "distribution = numpy.delete(distribution, numpy.s_[i:], 0)\n",
    "\n",
    "\n",
    "fig = pylab.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_aspect('equal')\n",
    "pylab.title('Uniform sampling inside the sphere\\n(only shown three intervals for z)')\n",
    "ax.set_xlabel('$x$', fontsize=14)\n",
    "ax.set_ylabel('$y$', fontsize=14)\n",
    "ax.set_zlabel('$z$', fontsize=14)\n",
    "pylab.plot(distribution[:,0], distribution[:,1], distribution[:,2],'.')\n",
    "pylab.show()\n",
    "pylab.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxwell and Boltzmann distributions\n",
    "- Monte Carlo program lacks the velocity if compared to Molecular Dynamics\n",
    "- Incorporate velocities int Statistical Mechanics with equiprobability\n",
    "- From Molecular Dynamics: $E_{\\text{kin}} = \\frac{1}{2}(\\vec{v}_0^2 + \\dots + \\vec{v}_{N-1}^2) = \\frac{1}{2}m \\sum_0^{N-1} \\vec{v}_i^2$\n",
    "- $\\vec{v}_k = \\begin{pmatrix}v_k^x \\\\ v_k^y\\\\ \\end{pmatrix}$\n",
    "- $\\vec{v}_k^2 = (v_k^x)^2 + (v_k^y)^2$\n",
    "- The sum is fixed for N particles, just like for a circle or sphere, only in dimension 2N\n",
    "- A legal set of velocities is point on a 2N-dim hypersphere\n",
    "    - If there is only one particle, the velocity is on a circle, indicating the direction of the particle.\n",
    "- Radios of the hypershpere: $r = \\sqrt{\\frac{2 E_{\\text{kin}}}{m}}$\n",
    "- Since in a closed system $\\frac{dE_{\\text{kin}}}{dt} = 0$ the radius has to remain constant as well\n",
    "- $\\pi(\\vec{v}_0, \\dots, \\vec{v}_{N-1}) = \\begin{cases}1 & \\text{if velocities are legal (on surface)}\\\\ 0 & \\text{otherwise}\\end{cases}$\n",
    "- $\\Rightarrow$ Set of velocities is a random vector on 2N-dim hyper sphere\n",
    "- Instead rescaling for the gaussian distribution we use a gaussian distribution with correct variance\n",
    "- $\\Rightarrow \\pi(v_x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{v_x^2}{2\\sigma^2}}$\n",
    "- $\\sigma = \\sqrt{\\frac{2}{m}\\frac{E_{\\text{kin}}}{dN}}$\n",
    "- $\\pi(v_x)$ is the Maxwell Distribution\n",
    "- $\\frac{E_{\\text{kin}}}{dN} =$ mean enery per degree of freedom $ = \\frac{1}{2} k_B T$\n",
    "- $T$: temperature (kelvin)\n",
    "- $k_B$: Boltzmann constant\n",
    "- $\\rightarrow \\sigma = \\sqrt{\\frac{k_B T}{m}}$\n",
    "- $\\pi(v_x) dv_x = \\sqrt{\\frac{m}{2\\pi k_B T}} \\exp(-\\frac{1}{2} \\frac{m v_x^2}{k_B T}) dv_x$\n",
    "- Absoulte values:\n",
    "- 2D: $\\pi(v) dv = \\frac{m}{k_B T} v \\exp(- \\frac{1}{2} \\frac{mv^2}{k_B T})dv$, since $dv_x dv_y = 2\\pi v dv$\n",
    "- 3D: $\\pi(v) dv = \\sqrt{\\frac{2}{\\pi}} \\left( \\frac{m}{k_B T} \\right)^{\\frac{3}{2}} v^2 \\exp(-\\frac{1}{2} \\frac{mv^2}{k_B T}) dv$\n",
    "\n",
    "\n",
    "- From Week2 the Molecular Dynamics\n",
    "- Histogram of each velocity component of an inidvidual particle is a Gaussian: $\\propto \\exp(-v^2)$\n",
    "- Probability distribution of the absolute value of the velocity of each particle is als give by a Gaussisan: $\\propto v \\exp(-v^2)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Maxwell Distribution for one particle and one component: $\\pi(v_x) \\propto \\exp\\left( -\\frac{1}{2} \\frac{mv_x^2}{k_B T} \\right)$\n",
    "- $\\propto \\exp \\left(- \\frac{E_{\\text{kin}\\{\\text{per component per particle}\\}}}{k_B T} \\right)$\n",
    "- However for changing E (two conected boxes): Boltzmann distribution: $\\pi(E) \\propto \\exp\\left(-\\frac{E}{k_B T}\\right)$\n",
    "- Boltzmann distribution is a generalization of Maxwell distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO event_disks_box.py from second week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Numbers\n",
    "- Generation of random numbers on computer\n",
    "- $\\Upsilon = $ `random.uniform(0.0, 1.0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Naive random number generator\n",
    "# random uses Mersenne Twister\n",
    "m = 134456 #magic\n",
    "n = 8121 #magic\n",
    "k = 28411 #magic\n",
    "idum = 1000 #Seed\n",
    "for iteration in range(10):\n",
    "    idum = (idum *  n + k) % m\n",
    "    ran = idum / float(m)\n",
    "    print(idum, ran, iteration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection Sampling\n",
    "- (reminder) Metropolis acceptance rate: $p(a \\rightarrow b) = \\min\\left(1, \\frac{\\pi(b)}{\\pi(a)} \\right)$\n",
    "- Comparing acceptance rate to random number between 0 and 1\n",
    "- If the random number is smaller than the acceptance rate the move is accepted, otherwise rejected\n",
    "- Sample on dimenional function: Gaussian distribution: $\\pi(x) = \\frac{e^{-x^2/2}}{\\sqrt{2\\pi}}$\n",
    "- In the code $p_{\\text{acc}} = \\frac{\\exp(-x^2_{\\text{new}}/2)}{\\exp(-x^2/2)}$\n",
    "- $\\rightarrow$ minimum is not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, math, pylab\n",
    "\n",
    "def markov_gauss(x, delta):\n",
    "    x_new = x + random.uniform(-delta, delta)\n",
    "    if random.uniform(0.0, 1.0) <  \\\n",
    "         math.exp (- x_new ** 2 / 2.0) / math.exp (- x ** 2 / 2.0): \n",
    "        return x_new \n",
    "    return x\n",
    "\n",
    "x = 0.0\n",
    "delta = 0.5\n",
    "data = []\n",
    "for k in range(50000):\n",
    "    x = markov_gauss(x, delta)\n",
    "    data.append(x)\n",
    "\n",
    "pylab.hist(data, 100, normed = 'True')\n",
    "x = [a / 10.0 for a in range(-50, 51)]\n",
    "y = [math.exp(- a ** 2 / 2.0) / math.sqrt(2.0 * math.pi) for a in x]\n",
    "pylab.plot(x, y, c='red', linewidth=2.0)\n",
    "pylab.title('Theoretical Gaussian distribution $\\pi(x)$ and \\\n",
    "    \\nnormalized histogram for '+str(len(data))+' samples', fontsize = 18)\n",
    "pylab.xlabel('$x$', fontsize = 30)\n",
    "pylab.ylabel('$\\pi(x)$', fontsize = 30)\n",
    "pylab.savefig('plot_markov_gauss.png')\n",
    "pylab.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Direct sampling rejection algorithm (!!!not rejections in a Markov chain)\n",
    "- Put Gaussion in a box from $-x_{\\text{cut}} < x < x_{\\text{cut}}$\n",
    "- Sample with monte carlo\n",
    "- Test if the sample is below the gaussian curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, math\n",
    "\n",
    "y_max = 1.0 / math.sqrt(2.0 * math.pi)\n",
    "x_cut = 5.0\n",
    "n_data = 1000\n",
    "n_accept = 0\n",
    "while n_accept < n_data:\n",
    "    y = random.uniform(0.0, y_max)\n",
    "    x = random.uniform(-x_cut, x_cut)\n",
    "    if y < math.exp( - x **2 / 2.0) / math.sqrt(2.0 * math.pi): \n",
    "        n_accept += 1\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x_{\\text{cut}}$ is a problematic value as it changes the acceptance rate ($x_{\\text{cut}} \\rightarrow \\infty$ will make the acceptance rate prohibitive $\\pi(x) \\approx 0$)\n",
    "- With distribution $\\pi(x) = \\frac{1}{2\\sqrt{x}} \\quad \\text{for } 0 < x \\leq 1$ selection of $y_{\\text{max}}$ is critical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, math, pylab\n",
    "\n",
    "y_max = 100.0\n",
    "x_cut = 1.0\n",
    "n_data = 10000\n",
    "data = []\n",
    "n_accept = 0\n",
    "while n_accept < n_data: \n",
    "    y = random.uniform(0.0, y_max)\n",
    "    x = random.uniform(0.0, x_cut)\n",
    "    if y < 1.0 / (2.0 * math.sqrt(x)):\n",
    "        n_accept += 1\n",
    "        data.append(x)\n",
    "\n",
    "pylab.hist(data, bins=100, normed='True')\n",
    "x = [a / 100.0 for a in range(1, 100)]\n",
    "y = [1.0 / (2.0 * math.sqrt(a)) for a in x]\n",
    "pylab.plot(x, y, 'red', linewidth = 2)\n",
    "pylab.title('Theoretical distribution $\\pi(x)={1}/{(2 \\sqrt{x})}$ and normalized\\\n",
    "    \\n histogram for '+str(n_accept)+' accepted samples',fontsize=16)\n",
    "pylab.xlabel('$x$', fontsize=18)\n",
    "pylab.ylabel('$\\pi(x)$', fontsize=18)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, math, pylab\n",
    "\n",
    "x = 0.2\n",
    "delta = 0.5\n",
    "data = []\n",
    "y_max = 0\n",
    "n_trials = 100000\n",
    "for k in range(n_trials):\n",
    "    x_new = x + random.uniform(-delta, delta)\n",
    "    if x_new > 0.0 and x_new < 1.0:\n",
    "        if random.uniform(0.0, 1.0) < math.sqrt(x) / math.sqrt(x_new): \n",
    "            x = x_new \n",
    "    if 1.0 / math.sqrt(x) > y_max: \n",
    "         y_max =  1.0 / math.sqrt(x)\n",
    "         # print y_max, x, k\n",
    "    data.append(x)\n",
    "\n",
    "pylab.hist(data, bins=100, normed='True')\n",
    "pylab.xlabel('$x$', fontsize=16)\n",
    "pylab.ylabel('$\\pi(x)$', fontsize=16)\n",
    "x = [a / 100.0 for a in range(1, 101)]\n",
    "y = [0.5 / math.sqrt(a) for a in x]\n",
    "pylab.plot(x, y, linewidth=1.5, color='r')\n",
    "pylab.title('Theoretical distribution $\\pi(x)={1}/{(2 \\sqrt{x})}$ and normalized\\\n",
    "    \\n histogram for '+str(len(data))+' samples',fontsize=16)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tower Sampling\n",
    "- Saturday night problem: Samling non-uniform finite distribution\n",
    "- $K$ possible evening activities, with different probabilities\n",
    "- $\\rightarrow$ troubles in sampling progability $\\Pi_0, \\dots, \\Pi_K$\n",
    "- Draw random number i: $0,1,\\dots, K-1$ to select activity p\n",
    "- Accept activity: `random.uniform(0, p_max) < p[i]`\n",
    "- !!! High rejection rate\n",
    "- rejection $ \\approx \\frac{\\Pi_{\\text{max}}}{<\\Pi>}$ is large\n",
    "- $\\Rightarrow$ **Tower Sampling**\n",
    "- Instead of chosing random number i, place the activities on a line next to each other, with width $= \\Pi_i$\n",
    "- $\\Rightarrow$ much faster, rejection free\n",
    "- Use bisection method to find the right activity on the line $\\Rightarrow O(\\log n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# bisection search to find the bin corresponding to eta\n",
    "def bisection_search(eta, w_cumulative):\n",
    "    kmin = 0\n",
    "    kmax = len(w_cumulative)\n",
    "    while True:\n",
    "        k = int((kmin + kmax) / 2)\n",
    "        if w_cumulative[k] < eta:\n",
    "            kmin = k\n",
    "        elif w_cumulative[k - 1] > eta:\n",
    "            kmax = k\n",
    "        else:\n",
    "            return k - 1\n",
    "\n",
    "# sample an integer number according to weights\n",
    "def tower_sample(weights):\n",
    "    sum_w = sum(weights)\n",
    "    w_cumulative = [0.0]\n",
    "    for l in range(len(weights)):\n",
    "        w_cumulative.append(w_cumulative[l] + weights[l])\n",
    "    eta = random.random() * sum_w\n",
    "    sampled_choice = bisection_search(eta, w_cumulative)\n",
    "    return sampled_choice\n",
    "\n",
    "weights = [0.4, 0.3, 0.8, 0.1, 0.2]\n",
    "n_samples = 10\n",
    "for sample in range(n_samples):\n",
    "    print(tower_sample(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walker algorithm\n",
    "- (Better then Tower Sampling)\n",
    "- Think of every possibility as a pile\n",
    "- Compute the average high $<\\Pi>$\n",
    "- If $\\Pi_i < <\\Pi>$ take a $\\Pi_j > <\\Pi>$ and place it on $i$. Put the remainder back on $j$\n",
    "- $\\Rightarrow$ Each pile consist of at most 2 different possibilities\n",
    "- Continue as with the naive approach\n",
    "- Draw random number i:  0,1,…,K−10,1,…,K−1  to select activity p\n",
    "- activity p is selected, if alone in this pil\n",
    "- if it shares: Accept activity p: random.uniform(0, p_max) < p[i]; activity q otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random, pylab\n",
    " \n",
    "N = 5\n",
    "pi = [[1.1 / 5.0, 0], [1.9 / 5.0, 1], [0.5 / 5.0, 2], [1.25 / 5.0, 3], [0.25 / 5.0, 4]]\n",
    "x_val = [a[1] for a in pi]\n",
    "y_val = [a[0] for a in pi]\n",
    "pi_mean = sum(y_val) / float(N)\n",
    "long_s = []\n",
    "short_s = []\n",
    "for p in pi:\n",
    "    if p[0] > pi_mean:\n",
    "        long_s.append(p)\n",
    "    else:\n",
    "        short_s.append(p)\n",
    "table = []\n",
    "for k in range(N - 1):\n",
    "    e_plus = long_s.pop()\n",
    "    e_minus = short_s.pop()\n",
    "    table.append((e_minus[0], e_minus[1], e_plus[1]))\n",
    "    e_plus[0] = e_plus[0] - (pi_mean - e_minus[0])\n",
    "    if e_plus[0] < pi_mean:\n",
    "        short_s.append(e_plus)\n",
    "    else:\n",
    "        long_s.append(e_plus)\n",
    "if long_s != []: \n",
    "    table.append((long_s[0][0], long_s[0][1], long_s[0][1]))\n",
    "else: \n",
    "    table.append((short_s[0][0], short_s[0][1], short_s[0][1]))\n",
    "\n",
    "#print(table)\n",
    "samples = []\n",
    "n_samples = 10000\n",
    "for k in range(n_samples):\n",
    "    Upsilon = random.uniform(0.0, pi_mean)\n",
    "    i = random.randint(0, N-1)\n",
    "    if Upsilon < table[i][0]:\n",
    "        samples.append(table[i][1])\n",
    "    else: samples.append(table[i][2])\n",
    "\n",
    "pylab.figure()\n",
    "pylab.hist(samples, bins=N, range=(-0.5, N-0.5), normed=True)\n",
    "pylab.plot(x_val, y_val,'ro', ms=8)\n",
    "pylab.title(\"Histogram using Walker's method for a discrete distribution\\n\\\n",
    "             on $N=$\"+str(N)+\" choices (\"+str(n_samples)+\" samples)\",fontsize=14)\n",
    "pylab.xlabel('$k$',fontsize=20)\n",
    "pylab.ylabel('$\\pi(k)$',fontsize=20)\n",
    "pylab.show()\n",
    "pylab.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tower Sampling: Continuum Limit\n",
    "- So far only discrete distributions now continuus\n",
    "- $\\pi(x)$ instead of $\\Pi_i$\n",
    "- Using tower sampling with descritized version of $\\pi(x)$\n",
    "- Having a tower of the weighted discrite x positions, we can then randomly pick a value\n",
    "- For fine discretizations, $O(\\log n)$ is still too high for the search inside the tower\n",
    "- Since distributions are positive, it can also be expressed as an integral\n",
    "- so $\\int_{-\\infty}^x dx' \\pi(x') = \\Phi(x)$\n",
    "- With a random number y (0,1) we then find the x with $\\Phi^{-1}(y)$\n",
    "- !!!Integral and its inverse needed\n",
    "- For Gaussian distribution it is $\\frac{1}{2} \\left[ 1 + \\text{erf}(\\frac{x}{\\sqrt{2}}) \\right]$\n",
    "- erf is the error function\n",
    "- Inverse: $x = \\sqrt{2} \\text{erf}^{-1}(2\\Phi -1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.special, random, math\n",
    "\n",
    "def gauss_transform():\n",
    "    Upsilon = random.uniform(0.0, 1.0)\n",
    "    x = math.sqrt(2.0) * scipy.special.erfinv(2.0 * Upsilon - 1.0)\n",
    "    return x\n",
    "\n",
    "n_trials = 10\n",
    "for trial in range(n_trials):\n",
    "    print(gauss_transform())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For $\\pi(x) = \\text{const} \\times x^{\\gamma} \\quad \\text{for } 0 < x \\leq 1$\n",
    "- Examle: $\\frac{1}{2\\sqrt{x}}$\n",
    "- Integral: $x^{1+\\gamma}$\n",
    "- InvIntegral: $\\Upsilon^{\\frac{1}{1+\\gamma}}$\n",
    "- $\\Upsilon = $ `random.uniform(0.0, 1.0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def gamma_transform(gamma):\n",
    "    x = (random.uniform(0.0, 1.0)) ** (1.0 / (gamma + 1.0))\n",
    "    return x\n",
    "\n",
    "gamma = -0.5\n",
    "n_trials = 10\n",
    "for trial in range(n_trials):\n",
    "    print(gamma_transform(gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\Rightarrow$ rejection free algorithm. No Markov Chain\n",
    "- This approach is hard for complicated functions are multidimensional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
